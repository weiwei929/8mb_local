# Review Backlog Assessment

## Document Quality Snapshot
- ✅ **Coverage:** The existing notes surface every high-signal issue we spotted while rescanning `backend-api/app` and the worker, so nothing critical is missing.
- ⚠️ **Prioritization gaps:** Several items with very different risk levels were grouped together (e.g., ffprobe error handling and cosmetic logging tweaks), making it hard to see what should land first.
- ✅ **Actionability:** Each recommendation maps cleanly to a concrete function or endpoint, so implementers have enough context once the priorities are rebalanced.

To address the prioritization concern, the backlog below reorders and merges the earlier bullets so that critical security and correctness work floats to the top.

## Ranked Remediation Backlog
1. **[Critical] Validate compression request paths.** `/api/compress` joins `UPLOADS_DIR` with the client-supplied `CompressRequest.filename` without normalizing it, so values like `"../../etc/passwd"` escape `/app/uploads` and let the worker process arbitrary host files. Guard the join with `resolve()`, reject traversal, and verify the job id matches the stored upload before dispatching Celery.
2. **[Critical] Sanitize uploaded filenames.** `/api/upload` writes files to `f"{job_id}_{file.filename}"` without stripping path separators. While it currently crashes on names containing `/`, a crafted request can still create confusing entries and leaves room for future traversal bugs. Strip to `Path(name).name`, collapse Unicode oddities, and reject empty results before writing.
3. **[High] Remove blocking Celery `.get()` calls from FastAPI handlers.** `_get_hw_info_cached()` and `_get_hw_info_fresh()` synchronously call `AsyncResult.get()` from inside async request handlers, pausing the entire event loop for up to 10 seconds per request. Offload those waits to a thread pool (e.g., `asyncio.to_thread`) or cache the values outside the loop so the API keeps serving traffic while the worker responds.
4. **[High] Harden ffprobe interactions.** `_ffprobe()` and the worker’s `ffprobe_info()` invoke `subprocess.run` without timeouts or structured exception handling, bubbling raw stderr to clients and leaving partial uploads behind. Add conservative timeouts, catch `TimeoutExpired` and other failures, clean up the staged file, and raise a purpose-built exception both sides can interpret.
5. **[High] Prevent duplicate cleanup scheduler startups.** Two separate `@app.on_event("startup")` hooks both call `start_scheduler()`, creating multiple APScheduler loops that fight each other. Consolidate scheduler bootstrapping into a single startup path or guard `start_scheduler()` with an idempotent flag.
6. **[High] Warm system capability caches correctly.** The second startup hook assigns `_ = system_capabilities` instead of awaiting the coroutine, so `SYSTEM_CAPS_CACHE` stays `None` until the first request pays the initialization cost. Call and await the coroutine (or a synchronous wrapper) during startup so telemetry endpoints stay fast and deterministic.
7. **[High] Align history download naming.** The history fallback rebuilds `stem + "_8mblocal" + ext`, but `/api/compress` now emits `stem_8mblocal_<task>.ext`, so history downloads silently fail. Mirror the new naming convention (including the task suffix) when reconstructing paths.
8. **[High] Add Redis failure handling to worker progress publishing.** `_publish()` in `worker/app/worker.py` assumes Redis writes always succeed; a transient outage raises and aborts the entire encode. Wrap publishes in try/except, log the error, and let the encode continue so jobs finish even if the UI stream flakes out.
9. **[Medium] Harden download fallbacks.** When Celery metadata or Redis provides a path, `/api/jobs/{task_id}/download` serves it without verifying it lives under `/app/outputs`. Resolve and compare prefixes before calling `FileResponse`, and treat unexpected locations as errors.
10. **[Medium] Validate numeric compression inputs.** Negative `target_size_mb`, `audio_bitrate_kbps`, or retention hours slip through the models today and only fail deep inside the worker. Add Pydantic constraints or explicit guards so the API rejects impossible values early.
11. **[Medium] Limit queue polling overhead.** `queue_status` currently calls `celery_app.AsyncResult` for every tracked job on every poll, multiplying broker round-trips under load. Cache recent Celery states, short-circuit finished tasks stored in Redis, or page through the active set to keep latency predictable.
12. **[Medium] Paginate and bound history responses.** `history_manager.get_history()` returns the full list each time, and the API relays it verbatim. Introduce pagination and server-side limits so large installations don’t ship megabyte-scale JSON blobs to the dashboard.
13. **[Medium] Normalize SSE logging volume.** `_sse_event_generator` logs every Redis message and heartbeat at info level, overwhelming logs during busy encodes. Downgrade repetitive entries to debug or gate them behind a verbosity flag to preserve signal.
14. **[Medium] Surface cleanup errors.** The scheduled cleanup silently swallows `os.remove` failures, hiding permission issues and stuck files. Catch and log exceptions with the offending path so operators can react when the disk stops draining.
15. **[Low] Document cleanup behavior.** Extend the operator documentation to describe how long uploads stick around, what the scheduler removes, and how to override retention. This reduces support load once the scheduler is fixed.
16. **[Low] Document GPU environment requirements.** Capture the expected NVIDIA/Intel runtime variables, driver versions, and container flags (see `gpu.html`) in ops docs so deployments reliably match the worker assumptions.
17. **[Low] Add automated regression tests.** Once filename validation and ffprobe hardening are in place, cover them with unit tests to prevent future regressions and give maintainers confidence when refactoring.
18. **[Low] Consolidate ffprobe exception types.** After introducing structured errors, expose a shared exception class so API and worker code can differentiate probe failures from other runtime errors without brittle string matching.
